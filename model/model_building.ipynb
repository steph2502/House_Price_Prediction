# House Price Prediction - Model Development

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load the dataset
print("Loading House Prices dataset...")
url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/kc_house_data.csv"

# Alternative: Use the Kaggle dataset structure
# For this example, I'll create a simulation based on the required features
# In practice, you should use: train_df = pd.read_csv('train.csv')

# For demonstration, let's load a house dataset and map to required features
try:
    df = pd.read_csv(url)
    print("Dataset loaded successfully!")
    
    # Map to required features format
    # Creating a mapping to match the required features
    data = pd.DataFrame({
        'OverallQual': np.random.randint(1, 11, len(df)),
        'GrLivArea': df['sqft_living'] if 'sqft_living' in df.columns else np.random.randint(500, 5000, len(df)),
        'TotalBsmtSF': df['sqft_basement'] if 'sqft_basement' in df.columns else np.random.randint(0, 2000, len(df)),
        'GarageCars': np.random.randint(0, 4, len(df)),
        'BedroomAbvGr': df['bedrooms'] if 'bedrooms' in df.columns else np.random.randint(1, 6, len(df)),
        'FullBath': df['bathrooms'].astype(int) if 'bathrooms' in df.columns else np.random.randint(1, 4, len(df)),
        'YearBuilt': df['yr_built'] if 'yr_built' in df.columns else np.random.randint(1900, 2020, len(df)),
        'Neighborhood': np.random.choice(['NAmes', 'CollgCr', 'OldTown', 'Edwards', 'Somerst'], len(df)),
        'SalePrice': df['price'] if 'price' in df.columns else np.random.randint(50000, 800000, len(df))
    })
    
except:
    # If URL fails, create sample data
    print("Creating sample dataset...")
    np.random.seed(42)
    n_samples = 1000
    
    data = pd.DataFrame({
        'OverallQual': np.random.randint(1, 11, n_samples),
        'GrLivArea': np.random.randint(500, 5000, n_samples),
        'TotalBsmtSF': np.random.randint(0, 2000, n_samples),
        'GarageCars': np.random.randint(0, 4, n_samples),
        'BedroomAbvGr': np.random.randint(1, 6, n_samples),
        'FullBath': np.random.randint(1, 4, n_samples),
        'YearBuilt': np.random.randint(1900, 2020, n_samples),
        'Neighborhood': np.random.choice(['NAmes', 'CollgCr', 'OldTown', 'Edwards', 'Somerst'], n_samples),
        'SalePrice': np.random.randint(50000, 800000, n_samples)
    })

print(f"\nDataset shape: {data.shape}")
print("\nFirst few rows:")
print(data.head())
print("\nDataset info:")
print(data.info())
print("\nBasic statistics:")
print(data.describe())

# 2. Data Preprocessing

print("\n" + "="*70)
print("DATA PREPROCESSING")
print("="*70)

# Select 6 features from the 9 available
# Features: OverallQual, GrLivArea, TotalBsmtSF, GarageCars, YearBuilt, Neighborhood
selected_features = ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'YearBuilt', 'Neighborhood']
target = 'SalePrice'

# Create working dataset
df_work = data[selected_features + [target]].copy()

# a. Handling missing values
print("\nMissing values before handling:")
print(df_work.isnull().sum())

# Fill missing values
for col in df_work.columns:
    if df_work[col].dtype in ['int64', 'float64']:
        df_work[col].fillna(df_work[col].median(), inplace=True)
    else:
        df_work[col].fillna(df_work[col].mode()[0], inplace=True)

print("\nMissing values after handling:")
print(df_work.isnull().sum())

# b. Feature selection - Already done (6 features selected)
print("\n" + "="*70)
print("FEATURE SELECTION")
print("="*70)
print(f"Selected features: {selected_features}")
print(f"Target variable: {target}")

# c. Encoding categorical variables
print("\n" + "="*70)
print("ENCODING CATEGORICAL VARIABLES")
print("="*70)

# Encode Neighborhood
le_neighborhood = LabelEncoder()
df_work['Neighborhood'] = le_neighborhood.fit_transform(df_work['Neighborhood'])
print(f"Neighborhood encoding: {dict(zip(le_neighborhood.classes_, le_neighborhood.transform(le_neighborhood.classes_)))}")

# Separate features and target
X = df_work[selected_features]
y = df_work[target]

print(f"\nFeature matrix shape: {X.shape}")
print(f"Target variable shape: {y.shape}")

# d. Feature scaling
print("\n" + "="*70)
print("FEATURE SCALING")
print("="*70)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=selected_features)

print("Feature scaling completed")
print("\nScaled features (first 5 rows):")
print(X_scaled.head())

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

print(f"\nTraining set size: {X_train.shape[0]}")
print(f"Testing set size: {X_test.shape[0]}")

# 3. Implement Random Forest Regressor
print("\n" + "="*70)
print("MODEL TRAINING - RANDOM FOREST REGRESSOR")
print("="*70)

model = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

# 4. Train the model
print("\nTraining the model...")
model.fit(X_train, y_train)
print("Model training completed!")

# 5. Evaluate the model
print("\n" + "="*70)
print("MODEL EVALUATION")
print("="*70)

# Predictions
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# Training metrics
train_mae = mean_absolute_error(y_train, y_pred_train)
train_mse = mean_squared_error(y_train, y_pred_train)
train_rmse = np.sqrt(train_mse)
train_r2 = r2_score(y_train, y_pred_train)

print("\nTRAINING SET METRICS:")
print(f"MAE (Mean Absolute Error): ${train_mae:,.2f}")
print(f"MSE (Mean Squared Error): ${train_mse:,.2f}")
print(f"RMSE (Root Mean Squared Error): ${train_rmse:,.2f}")
print(f"R² Score: {train_r2:.4f}")

# Testing metrics
test_mae = mean_absolute_error(y_test, y_pred_test)
test_mse = mean_squared_error(y_test, y_pred_test)
test_rmse = np.sqrt(test_mse)
test_r2 = r2_score(y_test, y_pred_test)

print("\nTESTING SET METRICS:")
print(f"MAE (Mean Absolute Error): ${test_mae:,.2f}")
print(f"MSE (Mean Squared Error): ${test_mse:,.2f}")
print(f"RMSE (Root Mean Squared Error): ${test_rmse:,.2f}")
print(f"R² Score: {test_r2:.4f}")

# Feature Importance
print("\n" + "="*70)
print("FEATURE IMPORTANCE")
print("="*70)

feature_importance = pd.DataFrame({
    'Feature': selected_features,
    'Importance': model.feature_importances_
}).sort_values('Importance', ascending=False)

print(feature_importance)

# Visualization
plt.figure(figsize=(10, 6))
plt.barh(feature_importance['Feature'], feature_importance['Importance'])
plt.xlabel('Importance')
plt.title('Feature Importance in House Price Prediction')
plt.tight_layout()
plt.savefig('feature_importance.png')
print("\nFeature importance plot saved as 'feature_importance.png'")

# 6. Save the trained model
print("\n" + "="*70)
print("SAVING MODEL AND PREPROCESSORS")
print("="*70)

# Save model
joblib.dump(model, 'house_price_model.pkl')
print("✓ Model saved as 'house_price_model.pkl'")

# Save scaler
joblib.dump(scaler, 'scaler.pkl')
print("✓ Scaler saved as 'scaler.pkl'")

# Save label encoder
joblib.dump(le_neighborhood, 'le_neighborhood.pkl')
print("✓ Label encoder saved as 'le_neighborhood.pkl'")

# Save feature names
joblib.dump(selected_features, 'feature_names.pkl')
print("✓ Feature names saved as 'feature_names.pkl'")

# Save neighborhood classes for reference
neighborhood_classes = le_neighborhood.classes_.tolist()
joblib.dump(neighborhood_classes, 'neighborhood_classes.pkl')
print("✓ Neighborhood classes saved")

# 7. Demonstrate reloading and prediction
print("\n" + "="*70)
print("DEMONSTRATING MODEL RELOADING")
print("="*70)

# Reload the model
loaded_model = joblib.load('house_price_model.pkl')
loaded_scaler = joblib.load('scaler.pkl')
loaded_le = joblib.load('le_neighborhood.pkl')
print("✓ Model and preprocessors reloaded successfully")

# Test prediction with sample data
sample_house = pd.DataFrame({
    'OverallQual': [7],
    'GrLivArea': [2000],
    'TotalBsmtSF': [1000],
    'GarageCars': [2],
    'YearBuilt': [2005],
    'Neighborhood': [0]  # NAmes encoded
})

print("\nSample House Data:")
print(sample_house)

# Scale the input
sample_scaled = loaded_scaler.transform(sample_house)

# Make prediction
prediction = loaded_model.predict(sample_scaled)

print(f"\nPredicted House Price: ${prediction[0]:,.2f}")

# Prediction with actual neighborhood name
print("\n" + "="*70)
print("EXAMPLE WITH NEIGHBORHOOD NAME")
print("="*70)

# Example house with neighborhood name
example_house = {
    'OverallQual': 8,
    'GrLivArea': 2500,
    'TotalBsmtSF': 1200,
    'GarageCars': 2,
    'YearBuilt': 2010,
    'Neighborhood': 'CollgCr'
}

print("House features:")
for key, value in example_house.items():
    print(f"  {key}: {value}")

# Encode neighborhood
example_house_encoded = example_house.copy()
example_house_encoded['Neighborhood'] = loaded_le.transform([example_house['Neighborhood']])[0]

# Create DataFrame
example_df = pd.DataFrame([example_house_encoded])

# Scale and predict
example_scaled = loaded_scaler.transform(example_df)
example_prediction = loaded_model.predict(example_scaled)

print(f"\nPredicted House Price: ${example_prediction[0]:,.2f}")

print("\n" + "="*70)
print("MODEL DEVELOPMENT COMPLETED SUCCESSFULLY!")
print("="*70)

# Summary
print("\nMODEL SUMMARY:")
print(f"Algorithm: Random Forest Regressor")
print(f"Features Used: {len(selected_features)}")
print(f"Test R² Score: {test_r2:.4f}")
print(f"Test RMSE: ${test_rmse:,.2f}")
print(f"Model saved: house_price_model.pkl")